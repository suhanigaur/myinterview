<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI Interview Chat</title>
  <link rel="stylesheet" href="styles.css">
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;600;700&display=swap" rel="stylesheet">
  <style>
    body {
      font-family: 'Poppins', sans-serif;
      margin: 0;
      background: #f4f9fc;
      color: #333;
    }
    header {
      background: #4b79a1;
      color: #fff;
      padding: 1rem 0;
      text-align: center;
    }
    .container {
      width: 90%;
      margin: 0 auto;
      max-width: 1200px;
    }
    main {
      display: flex;
      flex-wrap: wrap;
      justify-content: space-between;
      align-items: flex-start;
      padding: 1rem 0;
    }
    .chat-container {
      flex: 3;
      background: #fff;
      border-radius: 10px;
      box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.1);
      padding: 1rem;
      max-height: 650px;
      overflow-y: auto;
    }
    .camera-container {
      flex: 1.5;
      margin-left: 1rem;
      background: #fff;
      border-radius: 10px;
      box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.1);
      padding: 1rem;
      text-align: center;
    }
    .camera-container video {
      width: 100%;
      height: 100%;
      border-radius: 10px;
    }
    .button-container {
      display: flex;
      justify-content: center;
      margin: 1rem 0;
      gap: 1rem;
    }
    button {
      background: #4b79a1;
      color: #fff;
      border: none;
      padding: 0.8rem 1.5rem;
      font-size: 1rem;
      border-radius: 5px;
      cursor: pointer;
      transition: background 0.3s ease;
    }
    button:hover {
      background: #3b6f8c;
    }
    .progress-bar {
      margin: 1rem 0;
      height: 10px;
      background: #dbe9f4;
      border-radius: 5px;
      position: relative;
    }
    .progress {
      height: 100%;
      background: #4b79a1;
      border-radius: 5px;
      transition: width 0.3s ease;
      width: 0%;
    }
    .chat-message {
      margin: 1rem 0;
      display: flex;
      flex-direction: column;
    }
    .chat-message.ai {
      align-items: flex-start;
    }
    .chat-message.user {
      align-items: flex-end;
    }
    .chat-message span {
      display: inline-block;
      padding: 0.8rem;
      border-radius: 10px;
      max-width: 80%;
    }
    .chat-message.ai span {
      background: #e9f3fb;
      color: #333;
    }
    .chat-message.user span {
      background: #d1e7ff;
      color: #0056b3;
    }
    #feedbackBtn {
      display: none;
    }
  </style>
</head>
<body>
  <header>
    <div class="container">
      <h1>AI Interview Chat</h1>
      <a href="index.html" class="home-link"><button class="home-btn"><h2>Home</h2></button></a>
    </div>
  </header>
  <main class="container">
    <div class="chat-container" id="chat-container">
      <!-- Chat content will be dynamically added here -->
    </div>
    <div class="camera-container">
      <h2>Your Camera</h2>
      <video id="camera" autoplay></video>
    </div>
  </main>
  <div class="container">
    <div class="progress-bar">
      <div class="progress" id="progress"></div>
    </div>
    <div class="button-container">
      <button id="askQuestionBtn" onclick="startSpeaking()">Ask Question</button>
      <button id="recordBtn" onclick="toggleRecording()">Start Recording</button>
      <button id="feedbackBtn" onclick="redirectToFeedback()">Get Feedback</button>
    </div>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection"></script>
  <script>
    const chatContainer = document.getElementById('chat-container');
    const progress = document.getElementById('progress');
    const feedbackBtn = document.getElementById('feedbackBtn');
    const camera = document.getElementById('camera');
    let currentQuestionIndex = 0;
    const questions = [
      "What is your name?",
      "Tell me about your background.",
      "Why are you applying for this position?",
      "What are your strengths and weaknesses?"
    ];
    const userResponses = [];
    const synth = window.speechSynthesis;
    let recognition;
    let isRecording = false;

    let model, videoStream;
    const eyesNotLookingAlert = "Please maintain eye contact with the camera.";

    // Initialize SpeechRecognition
    if ('webkitSpeechRecognition' in window) {
      recognition = new webkitSpeechRecognition();
      recognition.continuous = false;
      recognition.interimResults = false;
      recognition.lang = 'en-US';

      recognition.onresult = function(event) {
        const transcript = event.results[0][0].transcript.trim();
        userResponses.push(transcript);
        addChatMessage("User", transcript);
      };

      recognition.onerror = function(event) {
        console.error("Speech recognition error:", event.error);
      };

      recognition.onend = function() {
        isRecording = false;
        document.getElementById('recordBtn').textContent = "Start Recording";
        if (currentQuestionIndex < questions.length) {
          startSpeaking();
        }
      };
    } else {
      alert("Speech Recognition is not supported in this browser.");
    }

    function startSpeaking() {
      if (currentQuestionIndex < questions.length) {
        const question = questions[currentQuestionIndex];
        const utterance = new SpeechSynthesisUtterance(question);
        synth.speak(utterance);
        addChatMessage("AI", question);
        currentQuestionIndex++;
        updateProgress();
        if (currentQuestionIndex === questions.length) {
          feedbackBtn.style.display = "block";
        }
      }
    }

    function addChatMessage(sender, message) {
      const messageDiv = document.createElement('div');
      messageDiv.classList.add('chat-message', sender.toLowerCase());
      const span = document.createElement('span');
      span.textContent = message;
      messageDiv.appendChild(span);
      chatContainer.appendChild(messageDiv);
      chatContainer.scrollTop = chatContainer.scrollHeight;
    }

    function updateProgress() {
      const progressWidth = (currentQuestionIndex / questions.length) * 100;
      progress.style.width = progressWidth + '%';
    }

    function toggleRecording() {
      if (!recognition) return;
      if (!isRecording) {
        isRecording = true;
        recognition.start();
        document.getElementById('recordBtn').textContent = "Stop Recording";
      } else {
        recognition.stop();
        document.getElementById('recordBtn').textContent = "Start Recording";
      }
    }

    function redirectToFeedback() {
      const feedbackData = {
        questions,
        userResponses
      };
      localStorage.setItem("feedbackData", JSON.stringify(feedbackData));
      window.location.href = "feedback.html";
    }

    // Camera functionality
    navigator.mediaDevices.getUserMedia({ video: true })
      .then(stream => {
        camera.srcObject = stream;
        videoStream = stream;
      })
      .catch(err => console.error("Camera Error:", err));

    // Initialize the face detection model
    async function loadFaceModel() {
      model = await faceLandmarksDetection.load(
        faceLandmarksDetection.SupportedPackages.mediapipeFacemesh
      );
      detectFace();
    }

    async function detectFace() {
      const videoElement = camera;
      const predictions = await model.estimateFaces({
        input: videoElement
      });

      if (predictions.length > 0) {
        const nose = predictions[0].annotations.nose;
        const eyeLeft = predictions[0].annotations.leftEye;
        const eyeRight = predictions[0].annotations.rightEye;
        const isLookingAway = !isEyeContact(nose, eyeLeft, eyeRight);

        if (isLookingAway) {
          alert(eyesNotLookingAlert);
        }
      }

      requestAnimationFrame(detectFace);
    }

    function isEyeContact(nose, eyeLeft, eyeRight) {
      const noseX = nose[3][0];
      const eyeLeftX = eyeLeft[3][0];
      const eyeRightX = eyeRight[3][0];

      const isLookingAway = noseX < eyeLeftX || noseX > eyeRightX;
      return !isLookingAway;
    }

    loadFaceModel();

    // Tab switch detection
    let lastFocusTime = Date.now();


    window.addEventListener("blur", () => {
      isTabFocused = false;
      alert("You switched tabs! Please stay focused on the interview.");
    });
    window.addEventListener("focus", () => {
      isTabFocused = true;
    });
  </script>
  <footer>
    <p>&copy; 2024 Interview.AI. All rights reserved.</p>
  </footer>
</body>
</html>
